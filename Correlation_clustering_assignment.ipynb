{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgo9yFR5gk53"
      },
      "source": [
        "This colab contains code for creating a correlation clustering problem defined by two weight matrices, W_plus and W_minus. You should add code to implement an approximation algorithm using semidefinite programming and randomized rounding, as described in [Williamson and Shmoys](https://www.designofapproxalgs.com/book.pdf) section 6.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDP9zhhSgbpN"
      },
      "source": [
        "# Construct weight matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qnLruc9_PxZZ"
      },
      "outputs": [],
      "source": [
        "# Fetch and import libraries\n",
        "#!pip install picos -q\n",
        "import picos as pc\n",
        "import cvxopt as cvx\n",
        "import cvxopt.lapack\n",
        "from scipy.linalg import cholesky\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yloKd7up4v54"
      },
      "outputs": [],
      "source": [
        "# Fetch data\n",
        "# !wget -q https://raw.githubusercontent.com/rasmus-pagh/apx/main/data/denmark-0.6.txt -O denmark-0.6.txt\n",
        "# !wget -q https://raw.githubusercontent.com/rasmus-pagh/apx/main/data/learning-0.6.txt -O learning-0.6.txt\n",
        "# !wget -q https://raw.githubusercontent.com/rasmus-pagh/apx/main/data/copenhagen-0.5.txt -O copenhagen-0.5.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsIhC-oYhcBm"
      },
      "source": [
        "There are three data files containing [GloVe](https://nlp.stanford.edu/projects/glove/) vectors, whose dot products measure the similarity between words. The matrix W_plus is defined as dot products of such vectors, while W_minus is constant, equaling the average in W_plus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eMSxFYXLTCH7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Place the file you want to work with last\n",
        "filename = 'learning-0.6.txt'\n",
        "filename = 'copenhagen-0.5.txt'\n",
        "filename = 'denmark-0.6.txt'\n",
        "\n",
        "# Read vectors and construct matrices\n",
        "with open(filename, 'r') as f:\n",
        "  feature_vectors = []\n",
        "  words = []\n",
        "  for line in f:\n",
        "    word, vector = line.split(';')\n",
        "    words.append(word)\n",
        "    vector = [ float(x) for x in vector.split(',') ]\n",
        "    feature_vectors.append(vector)\n",
        "  n = len(words)\n",
        "  feature_vectors = np.array(feature_vectors)\n",
        "  W_plus = np.dot(feature_vectors, np.transpose(feature_vectors))\n",
        "  W_minus = np.ones(shape=(n,n)) * np.average(W_plus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr2aTUfNotXa"
      },
      "source": [
        "# Correlation clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHOXaPSiNg6"
      },
      "source": [
        "Here you can implement your approximation algorithm. It may be helpful to consult the [implementation](https://colab.research.google.com/drive/1Rhe0kra6mqt5VHc2uTlNzJ_JC6kpG8nA?usp=sharing) of an approximation algorithm for Max Cut. Your implementation must:\n",
        "- Define and solve the semidefinite programming relaxation\n",
        "- Output the upper bound on OPT given by the relaxation\n",
        "- Output the expected value of the objective function with a random 4-clustering\n",
        "- Output the value of the best 4-clustering found using randomized rounding (say, in 100 trials), and the words placed in each cluster.\n",
        "\n",
        "If you experience problems with convergence (optimizer not terminating) don't worry about it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cA6kIO8Fiotu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inspecting denmark-0.6.txt...\n",
            "\n",
            "Semidefinite Program\n",
            "  maximize (⟨W_p, X⟩ + ⟨W_m, 1 - X⟩)/2\n",
            "  over\n",
            "    51×51 symmetric variable X\n",
            "  subject to\n",
            "    maindiag(X) = [1]\n",
            "    X ≽ 0\n",
            "    X ≥ 0\n",
            "    X ≤ [1]\n",
            "SDP upper bound on value: 814.9304216514133\n",
            "Expected value on this graph is 794.1511336003958.\n",
            "[[1.00000000e+00 9.74254263e-01 2.24702732e-01 ... 3.13039174e-02\n",
            "  8.75275826e-01 3.93821792e-01]\n",
            " [9.74254263e-01 1.00000000e+00 4.25670938e-01 ... 2.26704584e-01\n",
            "  7.95802699e-01 5.77135032e-01]\n",
            " [2.24702732e-01 4.25670938e-01 1.00000000e+00 ... 8.20888177e-01\n",
            "  3.86377602e-09 8.69672227e-01]\n",
            " ...\n",
            " [3.13039174e-02 2.26704584e-01 8.20888177e-01 ... 1.00000000e+00\n",
            "  6.33315528e-10 6.01085868e-01]\n",
            " [8.75275826e-01 7.95802699e-01 3.86377602e-09 ... 6.33315528e-10\n",
            "  1.00000000e+00 5.52884036e-09]\n",
            " [3.93821792e-01 5.77135032e-01 8.69672227e-01 ... 6.01085868e-01\n",
            "  5.52884036e-09 1.00000000e+00]]\n",
            "Found best value 811.2108202828251. The clusters are:\n",
            "['thailand' 'portugal' 'englan']\n",
            "['switzerland' 'belgium' 'finland' 'slovakia' 'holland' 'zealand' 'russia'\n",
            " 'bulgaria' 'czech' 'serbia' 'denmark' 'austria' 'lithuania' 'germany'\n",
            " 'slovenia' 'italy' 'norway' 'ireland' 'croatia' 'brazil' 'spain' 'greece'\n",
            " 'sweden' 'netherlands' 'latvia' 'romania' 'poland' 'hungary' 'iceland'\n",
            " 'belarus' 'azerbaijan' 'kazakhstan' 'estonia' 'morocco']\n",
            "['belanda' 'netherland' 'jerman']\n",
            "['brisbane' 'newcastle' 'melbourne' 'nz' 'australia' 'wales' 'london'\n",
            " 'europe' 'sydney' 'cardiff' 'england']\n"
          ]
        }
      ],
      "source": [
        "# Define the SDP \n",
        "def correlation_clustering():\n",
        "   filenames = ('learning-0.6.txt', 'copenhagen-0.5.txt', 'denmark-0.6.txt')\n",
        "   for filename in filenames:\n",
        "      with open(filename, 'r') as f:\n",
        "        feature_vectors = []\n",
        "        words = []\n",
        "        for line in f:\n",
        "          word, vector = line.split(';')\n",
        "          words.append(word)\n",
        "          vector = [ float(x) for x in vector.split(',') ]\n",
        "          feature_vectors.append(vector)\n",
        "        n = len(words)\n",
        "        feature_vectors = np.array(feature_vectors)\n",
        "        W_plus = np.dot(feature_vectors, np.transpose(feature_vectors))\n",
        "        W_minus = np.ones(shape=(n,n)) * np.average(W_plus)\n",
        "   \n",
        "      problem = pc.Problem()\n",
        "      X = pc.SymmetricVariable('X', (n,n))\n",
        "      W_p = pc.Constant('W_p', W_plus)\n",
        "      W_m = pc.Constant('W_m', W_minus)\n",
        "      ones = pc.Constant('1', np.ones((n,n)))\n",
        "      problem.add_constraint(pc.maindiag(X) == 1)\n",
        "      problem.add_constraint(X >> 0)\n",
        "      problem.add_constraint(X >= 0)\n",
        "      problem.add_constraint(X <= 1)\n",
        "      problem.set_objective('max', ((W_p | X) + (W_m | (ones - X)))/2)\n",
        "      print(f\"\\nInspecting {filename}...\\n\")\n",
        "      print(problem)\n",
        "      problem.solve(solver='cvxopt')\n",
        "      print(f\"SDP upper bound on value:\", problem.value)\n",
        "      X = np.clip(X.value, -1, 1)\n",
        "      EX = np.sum(\n",
        "         np.multiply(W_plus, (1 - 1/np.pi*np.arccos(X))**2).flatten() \n",
        "         + np.multiply(W_minus, (1 - (1 - 1/np.pi * np.arccos(X))**2)).flatten()\n",
        "         )/2\n",
        "      print(f\"Expected value on this graph is {EX}.\")\n",
        "      \n",
        "      max_value = 0\n",
        "      print(X)\n",
        "      for _ in range(100):\n",
        "         r1 = np.random.normal(size=n)\n",
        "         r2 = np.random.normal(size=n)\n",
        "         \n",
        "         R1 = np.logical_and(r1@X >= 0, r2@X >= 0)\n",
        "         R2 = np.logical_and(r1@X >= 0, r2@X  < 0)\n",
        "         R3 = np.logical_and(r1@X  < 0, r2@X >= 0)\n",
        "         R4 = np.logical_and(r1@X  < 0, r2@X  < 0)\n",
        "         Rs = (R1,R2,R3,R4)\n",
        "         \n",
        "         similarity_reward = 1/2*(\n",
        "            np.sum(W_plus[R1,:][:,R1]) \n",
        "            + np.sum(W_plus[R2,:][:,R2]) \n",
        "            + np.sum(W_plus[R3,:][:,R3]) \n",
        "            + np.sum(W_plus[R4,:][:,R4])\n",
        "            )\n",
        "         dissimilarity_reward = 1/2*(\n",
        "            np.sum(W_minus[R1,:][:,~R1])\n",
        "            + np.sum(W_minus[R2,:][:,~R2])\n",
        "            + np.sum(W_minus[R3,:][:,~R3])\n",
        "            + np.sum(W_minus[R4,:][:,~R4])\n",
        "         )\n",
        "         value = similarity_reward + dissimilarity_reward\n",
        "         \n",
        "         if value > max_value:\n",
        "            max_clustering = Rs\n",
        "            max_value = value\n",
        "      R1,R2,R3,R4 = max_clustering\n",
        "      word_array = np.array(words)\n",
        "      print(f\"Found best value {max_value}. The clusters are:\\n{word_array[R1]}\\n{word_array[R2]}\\n{word_array[R3]}\\n{word_array[R4]}\")\n",
        "   return max_clustering\n",
        "\n",
        "correlation_clustering()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
